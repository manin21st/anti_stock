import threading
import queue
import time
import logging
import uuid
import requests
from concurrent.futures import Future, CancelledError
from typing import Any, Callable, Dict, Optional, Tuple, Union
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)

# 우선순위 상수 (낮을수록 높음) - 외부 호환성을 위해 유지
PRIORITY_ORDER = 0      # 매수/매도 주문
PRIORITY_MANUAL = 1     # 수동 개입
PRIORITY_ACCOUNT = 2    # 잔고/예수금 조회
PRIORITY_DATA = 5       # 시세/차트 조회 (Default)
PRIORITY_BACKGROUND = 9 # 백그라운드 데이터 수집

@dataclass(order=True)
class APIRequest:
    priority: int
    timestamp: float
    request_id: str = field(compare=False)
    func: Callable = field(compare=False)
    args: tuple = field(compare=False, default_factory=tuple)
    kwargs: dict = field(compare=False, default_factory=dict)
    future: Future = field(compare=False, default_factory=Future)

class RateLimiterService:
    """
    [New Distributed Core]
    Replaces legacy logic with APIExecutor's Queue & TPS Server architecture.
    Maintains 'RateLimiterService' name for compatibility.
    """
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(RateLimiterService, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self, tps_limit: float = 2.0, tps_server_url: Optional[str] = None):
        if self._initialized: return
        
        self.tps_limit = tps_limit
        self.tps_server_url = tps_server_url
        # Client ID for Distributed TPS tracking
        import socket
        try:
            hostname = socket.gethostname()
        except:
            hostname = "unknown"
        pid = 0
        try:
            import os
            pid = os.getpid()
        except:
             pass
        self.client_id = f"{hostname}-{pid}-{uuid.uuid4().hex[:4]}"
        
        self.min_interval = 1.0 / max(tps_limit, 0.1)
        self.queue = queue.PriorityQueue()
        self.running = False
        self.thread = None
        
        # Pacing State
        self.last_dispatch_time = 0.0
        
        # Metrics
        self.execution_history = []  # (timestamp, priority, elapsed_wait)
        self.metrics_lock = threading.Lock()

        self._initialized = True
        
        # HTTP Session (Persistent Connection)
        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(pool_connections=1, pool_maxsize=1, max_retries=1)
        self.session.mount('http://', adapter)
        
        mode = f"Remote({tps_server_url})" if tps_server_url else "Local"
        logger.info(f"[RateLimiter] Initialized ({mode}). Limit={self.tps_limit} TPS (Interval={self.min_interval:.4f}s)")

        # Auto-start worker
        self.start()

    def configure(self, tps_limit: float = None, server_url: str = None):
        """Update configuration dynamically"""
        if tps_limit is not None:
            self.tps_limit = float(tps_limit)
            self.min_interval = 1.0 / self.tps_limit
            logger.info(f"[RateLimiter] TPS Limit updated to {self.tps_limit}")
        
        if server_url:
            self.tps_server_url = server_url.rstrip('/')
            mode = f"Remote({self.tps_server_url})"
            logger.info(f"[RateLimiter] Config updated: {mode}")

    def start(self):
        """Worker 스레드 시작"""
        with self._lock:
            if self.running: return
            self.running = True
            
            self.thread = threading.Thread(target=self._worker_loop, daemon=True, name="RateLimiterWorker")
            self.thread.start()
            logger.info("[RateLimiter] Worker Started.")

    def stop(self):
        """Worker 스레드 중지"""
        with self._lock:
            self.running = False
        
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=2.0)
            logger.info("[RateLimiter] Worker Stopped.")

    def execute(self, func: Callable, *args, **kwargs) -> Any:
        """
        [Synchronous Wrapper]
        Backward compatibility for legacy 'execute' calls.
        Blocks until result is available.
        Includes handling for EGW00201 (Rate Limit) retries.
        """
        # Extract priority if present in kwargs
        priority = kwargs.pop('priority', PRIORITY_DATA)
        
        max_retries = 10  # Increase retries for heavy startup load
        for attempt in range(max_retries):
            future = self.submit(func, *args, priority=priority, **kwargs)
            try:
                result = future.result()
                
                # Double-check for EGW00201 (Rate Limit Exceeded)
                is_rate_limit = False
                
                # Check error code
                if hasattr(result, 'getErrorCode') and result.getErrorCode() == "EGW00201":
                     is_rate_limit = True
                else:
                    # Scan all possible error message/content fields
                    msg_content = str(getattr(result, 'error_text', '')) + " " + \
                                  str(getattr(result, 'getErrorMessage', lambda: '')()) + " " + \
                                  str(result)
                    if "EGW00201" in msg_content:
                        is_rate_limit = True

                if is_rate_limit:
                     logger.warning(f"[RateLimiter] EGW00201 Rate Limit hit. Retrying ({attempt+1}/{max_retries})...")
                     time.sleep(1.0 + (attempt * 1.0)) # Exponential-ish backoff
                     continue
                
                return result
            except Exception as e:
                if "EGW00201" in str(e):
                     logger.warning(f"[RateLimiter] EGW00201 Exception. Retrying ({attempt+1}/{max_retries})...")
                     time.sleep(1.0 + (attempt * 1.0))
                     continue
                raise e
        
        return future.result() 

    def submit(self, func: Callable, *args, priority: int = PRIORITY_DATA, **kwargs) -> Future:
        """
        [New Capability] Async submission
        """
        request_id = uuid.uuid4().hex
        timestamp = time.time()
        future = Future()
        
        req = APIRequest(priority, timestamp, request_id, func, args, kwargs, future)
        self.queue.put(req)
        return future

    def _worker_loop(self):
        while self.running:
            try:
                # 1. Fetch Request
                try:
                    req: APIRequest = self.queue.get(timeout=1.0)
                except queue.Empty:
                    continue

                if req.future.cancelled():
                    self.queue.task_done()
                    continue

                # 2. Pacing / Token Control
                if self.tps_server_url:
                    self._wait_for_server_token()
                else:
                    self._wait_local_pacing()

                # 3. Execution (Synchronous Call)
                dispatch_start = time.time()
                try:
                    # Update dispatch time (Self-Update)
                    self.last_dispatch_time = dispatch_start
                    
                    result = req.func(*req.args, **req.kwargs)
                    
                    if not req.future.cancelled():
                        req.future.set_result(result)
                        
                except Exception as e:
                    if not req.future.cancelled():
                        req.future.set_exception(e)
                finally:
                    self.queue.task_done()
                    
                    # Metrics
                    with self.metrics_lock:
                        elapsed_wait = dispatch_start - req.timestamp
                        self.execution_history.append((dispatch_start, req.priority, elapsed_wait))
                        if len(self.execution_history) > 1000:
                            self.execution_history.pop(0)

            except Exception as e:
                logger.error(f"[RateLimiter] Worker Logic Crash: {e}", exc_info=True)
                time.sleep(1.0)

    def _wait_local_pacing(self):
        """Strict Local Token Bucket / Pacing"""
        now = time.time()
        elapsed = now - self.last_dispatch_time
        wait_needed = self.min_interval - elapsed
        
        if wait_needed > 0:
            time.sleep(wait_needed)

    def _wait_for_server_token(self):
        """
        Communicates with centralized TPS server.
        Blocks until a token is granted.
        """
        while self.running:
            try:
                resp = self.session.get(f"{self.tps_server_url}/token", 
                                        headers={"X-Client-ID": self.client_id}, 
                                        timeout=2.0)
                
                if resp.status_code == 200:
                    return # Granted
                elif resp.status_code == 429:
                    # Remote limit hit
                    time.sleep(0.1) # Short wait
                    continue
                else:
                    logger.warning(f"[RateLimiter] Server error {resp.status_code}. Fallback local.")
                    self._wait_local_pacing()
                    return

            except requests.exceptions.RequestException:
                # logger.warning("[RateLimiter] Server unreachable. Fallback local.")
                self._wait_local_pacing()
                return

    def get_stats(self) -> Dict[str, Any]:
        return {
            "queue_size": self.queue.qsize(),
            "tps_limit": self.tps_limit,
            "mode": "Remote" if self.tps_server_url else "Local"
        }

# Singleton Instance (Legacy Name)
params_limiter = RateLimiterService()
